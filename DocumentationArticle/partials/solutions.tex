\section{Przegląd dostępnych rozwiązań dostępnych na rynku}
\label{sec:solutions}

\subsection{Hadoop}
\label{sec:solutions:hadoop}
Hadoop to darmowy framework rozwijany przez firmę Apache. Jest to framework oparty o język Java, który wspiera przetwarzanie  dużych zbiorów danych w rozproszonym środowisku obliczeniowym. Hadoop umożliwia uruchomienie aplikacji na systemie z tysiącami węzłów obejmujących tysiące terabajtów danych. Jego rozproszony system plików umożliwia szybkie przesyłanie danych pomiędzy poszczególnymi węzłami oraz działa nieprzerwanie w przypadku awarii węzła. To podejście zmniejsza  ryzyko wystąpienia awarii systemy, nawet jeśli znacząca ilość węzłów ulegnie awarii. Obecnie Hadoop zawiera:

\begin{itemize}[noitemsep]
\item jądro Hadoop
\item MapReduce
\item rozproszony system plików Hadoop (HDFS
\end{itemize}

Największymi zaletami Hadoop są:
\begin{itemize}[noitemsep]
\item niezawodność (nawet w przypadku awarii węzłów system dalej działa)
\item skalowalność
\item rozproszenie
\end{itemize}

\subsection{Hive}
\label{sec:solutions:hive}
Apache Hive to projekt, który umożliwia tworzenie kwerend i zarządzanie dużym zbiorem danych znajdujących się w pamięci rozproszonej. Hive wykorzystuje prosty język zapytań podobny do języka SQL. Język ten nazwany został QL. Język ten umożliwia tworzenie zapytań podobnych do zapytań SQL i umożliwia tworzenie własnych funkcji mapujących i redukujących przez użytkowników, którzy znają framework Map/Reduce. Język QL wykorzystywany przez Hive może być rozszerzony przez funkcje skalarne(UDF), agregujące (UDAF) i funkcje tablicowe (UDTF).

Apache Hive posiada:

\begin{itemize}[noitemsep]
\item narzędzia ułatwiających proces ETL,
\item mechanizm do przetwarzania różnych formatów danych,
\item zapytania wykonywane przy pomocy Map/Reduce
\end{itemize}

Hive nie oferuje przetwarzania zapytań w czasie rzeczywistym i aktualizacji wierszy o niskim narzucie czasowym. Hive najlepiej wykorzystać do dużych zbiorów danych, które ciągle napływają. Największymi zaletami Hive są:

\begin{itemize}[noitemsep]
\item skalowalność (skaluje się poprzez dodanie dodatkowych dynamicznych klastrów do Hadoop)
\item rozszerzalność ( MapReduce framework, UDF/UDA/UDTF)
\item tolerancja błędów
\end{itemize}

Hive zawiera HCatalog i WebHCat. HCatalog jest warstwą zarządzającą tabelami i pamięcią dla Hadoop, która możliwa użytkownikowi korzystać z różnych narzędzi do przetwarzania danych (np. MapReduce) w celu łatwiejszego odczytu i zapisu danych. WebHCat oferuje usługi, które umożliwiają uruchomienia na Hadoop'ie MapReduce, zadań Hive lub wykonać operację metadanową za pomocą protokołu HTTP(REST).

\subsection{Spark (Stream Spark)}
\label{sec:solutions:spark}

Apache Spark to projekt, którego częścią jest Apache Spark Streaming, czyli framework, który umożliwia przetwarzanie strumieniowych, stale napływających o dużej częstotliwości danych w czasie rzeczywistym. Dane mogą pochodzić z różnych źródeł, takich jak Kafka, Flume, ZeroMQ, czy natywne gniazda TCP (czyli implementacja zaproponowana w \ref{sec:eventgenerator-eventreceiver}). Przetworzone dane mogą być składowane na dysku, w bazach danych, wysyłane na szyny danych. Spark dostarcza również wbudowane algorytmy uczenia maszynowego (ang. \emph{machine learning}) oraz analizowania grafów (ang. \emph{graph processing}). Dane są definiowane pojęciem RDD\cite{manual-apache-spark-streaming} i nie zmieniają swojego stanu (\emph{immutable state}).

\begin{figure}[h!]
  \centering
    \includegraphics[scale=0.75]{spark-streaming-arch.png}
  \caption{Zasada działania Apache Spark Stream}
  \label{fig:spark-streaming-arch}
\end{figure}

Apache Spark Streaming umożliwia również obliczenia na przesuwnym oknie RDD:

\begin{figure}[h!]
  \centering
    \includegraphics[scale=0.75]{spark-streaming-dstream-window.png}
  \caption{Przesuwne okno czasowe w Apache Spark Streaming}
  \label{fig:spark-streaming-dstream-window}
\end{figure}

Wykorzystanie Spark Streaming umożliwia wykonywanie operacji na strumieniu danych znanych z MapReduce oraz strumieniowych baz danych, w szczególności:

\begin{itemize}[noitemsep]
  \item map
  \item reduce
  \item filter
  \item transform
  \item union - złączenie źródeł danych
  \item count oraz countByValue
\end{itemize}
